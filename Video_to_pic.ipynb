{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python==3.4.2.16\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/26/9c631442c828ec88d4b0017ec39bb6ed655d81b3e99010ad1c841d104d54/opencv_contrib_python-3.4.2.16-cp36-cp36m-macosx_10_6_x86_64.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/judytraj/anaconda3/lib/python3.6/site-packages (from opencv-contrib-python==3.4.2.16) (1.17.3)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "  Found existing installation: opencv-contrib-python 3.2.0.7\n",
      "    Uninstalling opencv-contrib-python-3.2.0.7:\n",
      "      Successfully uninstalled opencv-contrib-python-3.2.0.7\n",
      "Successfully installed opencv-contrib-python-3.4.2.16\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python==3.4.2.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/94/46dcae8c061e28be31bcaa55c560cb30ee9403c9a4bb2659768ec1b9eb7d/imutils-0.5.3.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-cp36-none-any.whl size=25851 sha256=affd62f4af06ecfc102f31873f6a438d51d31544302f7f9de0a031945dafc375\n",
      "  Stored in directory: /Users/judytraj/Library/Caches/pip/wheels/16/84/1f/bf88641293cda2c8be81a5c4b8ca973dd9125a6dc3767417fd\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stitcher:\n",
    "    def __init__(self):\n",
    "        self.isv3 = imutils.is_cv3(or_better=True)\n",
    "        \n",
    "    def stitch(self, images, ratio=0.75, reprojThresh=4.0,\n",
    "        showMatches=False):\n",
    "        # unpack the images, then detect keypoints and extract local invariant descriptors from them\n",
    "        (imageB, imageA) = images\n",
    "        (kpsA, featuresA) = self.detectAndDescribe(imageA)\n",
    "        (kpsB, featuresB) = self.detectAndDescribe(imageB)\n",
    "\n",
    "        # match features between the two images\n",
    "        M = self.matchKeypoints(kpsA, kpsB,\n",
    "            featuresA, featuresB, ratio, reprojThresh)\n",
    "\n",
    "        # if the match is None, then there aren't enough matched keypoints to create a panorama\n",
    "        if M is None:\n",
    "            return None\n",
    "        # otherwise, apply a perspective warp to stitch the images together\n",
    "        (matches, H, status) = M\n",
    "        result = cv2.warpPerspective(imageA, H,\n",
    "            (imageA.shape[1] + imageB.shape[1], imageA.shape[0]))\n",
    "        result[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n",
    "\n",
    "        # check to see if the keypoint matches should be visualized\n",
    "        if showMatches:\n",
    "            vis = self.drawMatches(imageA, imageB, kpsA, kpsB, matches,\n",
    "                status)\n",
    "\n",
    "            # return a tuple of the stitched image and the visualization\n",
    "            return (result, vis)\n",
    "\n",
    "        # return the stitched image\n",
    "        return result\n",
    "    \n",
    "    def detectAndDescribe(self, image):\n",
    "        # convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect and extract features from the image\n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "        (kps, features) = descriptor.detectAndCompute(image, None)\n",
    "\n",
    "        # convert the keypoints from KeyPoint objects to NumPy arrays\n",
    "        kps = np.float32([kp.pt for kp in kps])\n",
    "\n",
    "        # return a tuple of keypoints and features\n",
    "        return (kps, features)\n",
    "    \n",
    "    def matchKeypoints(self, kpsA, kpsB, featuresA, featuresB,\n",
    "        ratio, reprojThresh):\n",
    "        # compute the raw matches and initialize the list of actual matches\n",
    "        matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "        rawMatches = matcher.knnMatch(featuresA, featuresB, 2)\n",
    "        matches = []\n",
    "\n",
    "        # loop over the raw matches\n",
    "        for m in rawMatches:\n",
    "            # ensure the distance is within a certain ratio of each\n",
    "            # other (i.e. Lowe's ratio test)\n",
    "            if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "                matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "                \n",
    "        # computing a homography requires at least 4 matches\n",
    "        if len(matches) > 4:\n",
    "            # construct the two sets of points\n",
    "            ptsA = np.float32([kpsA[i] for (_, i) in matches])\n",
    "            ptsB = np.float32([kpsB[i] for (i, _) in matches])\n",
    "\n",
    "            # compute the homography between the two sets of points\n",
    "            (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC,\n",
    "                reprojThresh)\n",
    "\n",
    "            # return the matches along with the homograpy matrix and status of each matched point\n",
    "            return (matches, H, status)\n",
    "\n",
    "        # otherwise, no homograpy could be computed\n",
    "        return None\n",
    "    \n",
    "    def drawMatches(self, imageA, imageB, kpsA, kpsB, matches, status):\n",
    "        # initialize the output visualization image\n",
    "        (hA, wA) = imageA.shape[:2]\n",
    "        (hB, wB) = imageB.shape[:2]\n",
    "        vis = np.zeros((max(hA, hB), wA + wB, 3), dtype=\"uint8\")\n",
    "        vis[0:hA, 0:wA] = imageA\n",
    "        vis[0:hB, wA:] = imageB\n",
    "\n",
    "        # loop over the matches\n",
    "        for ((trainIdx, queryIdx), s) in zip(matches, status):\n",
    "            # only process the match if the keypoint was successfully matched\n",
    "            if s == 1:\n",
    "                # draw the match\n",
    "                ptA = (int(kpsA[queryIdx][0]), int(kpsA[queryIdx][1]))\n",
    "                ptB = (int(kpsB[trainIdx][0]) + wA, int(kpsB[trainIdx][1]))\n",
    "                cv2.line(vis, ptA, ptB, (0, 255, 0), 1)\n",
    "\n",
    "        # return the visualization\n",
    "        return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens the Video file\n",
    "cap= cv2.VideoCapture('Video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=1\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imwrite('img'+str(count)+'.jpg',frame)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitcher = Stitcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = cv2.imread('img2.jpg')\n",
    "imgB = cv2.imread('img1.jpg')\n",
    "imageA = imutils.resize(imgA, width=400)\n",
    "imageB = imutils.resize(imgB, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)\n",
    "cv2.imwrite('out.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "while(i<count):\n",
    "    imgA = cv2.imread('img'+str(i)+'.jpg')\n",
    "    imgB = cv2.imread('out.jpg')\n",
    "    (result, vis) = stitcher.stitch([imgA, imgB], showMatches=True)\n",
    "    cv2.imwrite('out.jpg', result)\n",
    "    i+=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
